{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92535934.5816974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1024x1024 1643.2ms\n",
      "Speed: 3.3ms preprocess, 1643.2ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "0: 1024x1024 1734.2ms\n",
      "Speed: 6.0ms preprocess, 1734.2ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 8\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "storage tank: diameter = 5.82 meters, width = 5.87 meters, height = 5.78 meters\n",
      "storage tank: diameter = 5.89 meters, width = 5.93 meters, height = 5.84 meters\n",
      "storage tank: diameter = 5.93 meters, width = 5.99 meters, height = 5.87 meters\n",
      "storage tank: diameter = 5.98 meters, width = 6.01 meters, height = 5.95 meters\n",
      "storage tank: diameter = 5.92 meters, width = 5.97 meters, height = 5.87 meters\n",
      "storage tank: diameter = 6.38 meters, width = 6.81 meters, height = 5.94 meters\n",
      "storage tank: diameter = 4.99 meters, width = 5.58 meters, height = 4.41 meters\n",
      "storage tank: diameter = 4.67 meters, width = 5.74 meters, height = 3.61 meters\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "0: 1024x1024 1911.5ms\n",
      "Speed: 3.8ms preprocess, 1911.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "0: 1024x1024 1439.6ms\n",
      "Speed: 5.8ms preprocess, 1439.6ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 1\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "storage tank: diameter = 1.88 meters, width = 1.89 meters, height = 1.87 meters\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "0: 1024x1024 (no detections), 1315.1ms\n",
      "Speed: 9.7ms preprocess, 1315.1ms inference, 0.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "0: 1024x1024 1332.1ms\n",
      "Speed: 6.2ms preprocess, 1332.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 10\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "storage tank: diameter = 4.43 meters, width = 4.43 meters, height = 4.43 meters\n",
      "storage tank: diameter = 4.62 meters, width = 4.67 meters, height = 4.58 meters\n",
      "storage tank: diameter = 4.91 meters, width = 4.93 meters, height = 4.88 meters\n",
      "storage tank: diameter = 4.44 meters, width = 4.45 meters, height = 4.44 meters\n",
      "storage tank: diameter = 3.81 meters, width = 3.83 meters, height = 3.79 meters\n",
      "storage tank: diameter = 5.01 meters, width = 5.08 meters, height = 4.95 meters\n",
      "storage tank: diameter = 4.90 meters, width = 4.94 meters, height = 4.87 meters\n",
      "storage tank: diameter = 4.50 meters, width = 4.54 meters, height = 4.46 meters\n",
      "storage tank: diameter = 4.85 meters, width = 4.92 meters, height = 4.77 meters\n",
      "storage tank: diameter = 5.31 meters, width = 5.99 meters, height = 4.64 meters\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "0: 1024x1024 2550.4ms\n",
      "Speed: 11.8ms preprocess, 2550.4ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "0: 1024x1024 (no detections), 2465.7ms\n",
      "Speed: 5.2ms preprocess, 2465.7ms inference, 0.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "0: 1024x1024 (no detections), 1530.5ms\n",
      "Speed: 4.2ms preprocess, 1530.5ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "0: 1024x1024 1549.7ms\n",
      "Speed: 4.3ms preprocess, 1549.7ms inference, 0.7ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "0: 1024x1024 1864.8ms\n",
      "Speed: 5.7ms preprocess, 1864.8ms inference, 1.2ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "0: 1024x1024 (no detections), 2061.3ms\n",
      "Speed: 3.5ms preprocess, 2061.3ms inference, 0.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "0: 1024x1024 1752.4ms\n",
      "Speed: 4.4ms preprocess, 1752.4ms inference, 2.4ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "0: 1024x1024 1749.3ms\n",
      "Speed: 7.6ms preprocess, 1749.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from location import load_all_locations, calculate_distance_components\n",
    "\n",
    "locations = load_all_locations()\n",
    "len(locations)\n",
    "\n",
    "locations_dict = {loc.name: loc for loc in locations}\n",
    "for loc in locations:\n",
    "    loc.examples = list(loc.tiles.keys())[0:3]\n",
    "locations[0].examples = [\n",
    "(51.939564, 4.065469),\n",
    "(51.939564, 4.072755),\n",
    "(51.939564, 4.138326),\n",
    "]\n",
    "locations[1].examples = [\n",
    "(25.665964, -80.608233),\n",
    "(25.670456, -80.548431),\n",
    "(25.670456, -80.588299),\n",
    "]\n",
    "location = locations[1]\n",
    "print(calculate_distance_components(location.top_left, location.bottom_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "def pil_to_base64(image, format=\"PNG\"):\n",
    "    \"\"\"\n",
    "    Convert a PIL image to a Base64-encoded string.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image): The PIL image to convert.\n",
    "        format (str): The format to save the image (e.g., \"PNG\", \"JPEG\").\n",
    "\n",
    "    Returns:\n",
    "        str: Base64-encoded image string.\n",
    "    \"\"\"\n",
    "    # Create a bytes buffer\n",
    "    buffer = io.BytesIO()\n",
    "    \n",
    "    # Save the image to the buffer in the specified format\n",
    "    image.save(buffer, format=format)\n",
    "    \n",
    "    # Get the byte data from the buffer\n",
    "    buffer.seek(0)\n",
    "    image_bytes = buffer.read()\n",
    "    \n",
    "    # Encode the byte data to Base64\n",
    "    base64_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    \n",
    "    return base64_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "css_style = \"\"\"\n",
    ".container {\n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    align-items: center;\n",
    "    margin: 20px auto;\n",
    "}\n",
    ".row {\n",
    "    display: flex;\n",
    "    flex-direction: row;\n",
    "    align-items: center;\n",
    "    width: 80%;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #ccc;\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.1);\n",
    "}\n",
    ".index {\n",
    "    flex: 1;\n",
    "    text-align: center;\n",
    "    font-weight: bold;\n",
    "    color: #333;\n",
    "}\n",
    ".image {\n",
    "    flex: 3;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    "img {\n",
    "    max-width: 100%;\n",
    "    height: auto;\n",
    "    border-radius: 5px;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot.rschatgpt import initilize_bot, analyze_image\n",
    "\n",
    "\n",
    "#bot = RSChatGPT(gpt_name=\"gpt-4o-2024-11-20\")\n",
    "def process_individual(prompt, image, bot, threshold=.5, resolution=0.1): \n",
    "\n",
    "    # Save the image to a temporary file\n",
    "    print(bot)\n",
    "    result_list, image_out = analyze_image(bot, image, prompt, threshold, resolution)\n",
    "    \n",
    "    #response = bot.run_text(prompt, result_list)\n",
    "    return result_list, image, image_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bot.rschatgpt.RSChatGPT object at 0x3288d2c70>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from time import sleep\n",
    "ex_prompt1 = \"Count ships!\"\n",
    "ex_prompt2 = \"Count ships! Show how you did it.\"\n",
    "\n",
    "def process_individually(prompt: str, images: list[Image.Image], pixels_per_meter:float, bot, threshold) -> list:\n",
    "    return [process_individual(prompt, image, bot, threshold, pixels_per_meter) for image in images]\n",
    "\n",
    "def process_examples(prompt, location, bot, threshold=.5):\n",
    "    #location.create_example_images() # to create random examples\n",
    "    example_images = [location.tiles[example] for example in location.examples]\n",
    "    return process_individually(prompt, example_images, location.meters_per_pixel, bot, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x32a5a3280>\n",
      "\n",
      "0: 1024x1024 1505.0ms\n",
      "Speed: 9.3ms preprocess, 1505.0ms inference, 1.3ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 0\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "\n",
      "\n",
      "Question:\n",
      "How many storage tanks are there?\n",
      "\n",
      "0: 1024x1024 1786.4ms\n",
      "Speed: 21.1ms preprocess, 1786.4ms inference, 0.8ms postprocess per image at shape (1, 3, 1024, 1024)\n",
      "Prompt:\n",
      " Answer the question about the image based on the given objects' properties.\n",
      "Note that 'large vehicle' and 'small vehicle' are cars. Output only a single number as your output between double square brackets as, e.g [[6]].\n",
      "\n",
      "Number of objects:\n",
      "plane: 0\n",
      "ship: 0\n",
      "storage tank: 1\n",
      "ground track field: 0\n",
      "large vehicle: 0\n",
      "small vehicle: 0\n",
      "helicopter: 0\n",
      "\n",
      "Objects properties:\n",
      "storage tank: diameter = 5.99 meters, width = 6.12 meters, height = 5.86 meters\n",
      "\n",
      "Question:\n",
      "Count the storage tanks\n",
      "\n",
      "<bot.rschatgpt.RSChatGPT object at 0x321ad3190>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import base64\n",
    "import gradio as gr\n",
    "from time import sleep\n",
    "\n",
    "# Specify your folder containing the images\n",
    "image_folder = \"img/\"\n",
    "\n",
    "\n",
    "# Load image file paths\n",
    "image_paths = sorted(Path(image_folder).glob(\"*.png\")) + sorted(Path(image_folder).glob(\"*.jpg\"))\n",
    "image_data = [(index, str(path)) for index, path in enumerate(image_paths)]\n",
    "\n",
    "# CSS to style the layout\n",
    "\n",
    "# Function to generate HTML content for images\n",
    "\n",
    "\n",
    "css_style = \"\"\"\n",
    ".row_s {\n",
    "    display: flex;\n",
    "    flex-direction: row;\n",
    "    align-items: center;\n",
    "    width: 100%;\n",
    "    margin-bottom: 30px;\n",
    "    gap: 20px;\n",
    "    justify-content: space-between; /* Adjust spacing behavior */\n",
    "}\n",
    ".index {\n",
    "    flex: 1;\n",
    "    text-align: center;\n",
    "    font-weight: bold;\n",
    "    color: #333;\n",
    "    font-size: 1.5em;\n",
    "}\n",
    ".image {\n",
    "    width: 40%;\n",
    "    height: auto; \n",
    "    display: block; /* Center-align image inside a parent element if needed */\n",
    "}\n",
    "#gr-header {\n",
    "    font-size: 4em !important; /* Force the size to apply */\n",
    "    font-weight: bold;\n",
    "    margin-bottom: 20px;\n",
    "    text-align: center; \n",
    "    color: #0056b3;\n",
    "}\n",
    "body {\n",
    "    width: 100%;\n",
    "    font-family: 'Arial', sans-serif; /* Modern font */\n",
    "    color: #333; /* Dark text for readability */\n",
    "    margin: 0;\n",
    "    padding: 0;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    padding: 20px;\n",
    "    background-color: #f9f9f9; /* Light gray background for contrast */\n",
    "}\n",
    "\n",
    "h1, h2, h3, h4, h5, h6 {\n",
    "    color: #0056b3; /* Accent color for headers */\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    ".gr-dropdown, .gr-input {\n",
    "    margin-bottom: 15px;\n",
    "    padding: 8px;\n",
    "    border-radius: 5px;\n",
    "    border: 1px solid #ced4da;\n",
    "    font-size: 0.95em;\n",
    "    line-height: 1.2em;\n",
    "    background-color: #ffffff;\n",
    "}\n",
    "\n",
    ".gr-html {\n",
    "    font-size: 1em;\n",
    "    color: #333;\n",
    "    margin-top: 10px;\n",
    "}\n",
    "\n",
    ".gr-chatbot {\n",
    "    max-height: 400px; \n",
    "    overflow-y: auto;\n",
    "    border: 1px solid #ced4da;\n",
    "    padding: 10px;\n",
    "    border-radius: 8px;\n",
    "    background: #ffffff; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "js = \"\"\"\n",
    "function createGradioAnimation() {\n",
    "    var container = document.createElement('div');\n",
    "    container.id = 'gradio-animation';\n",
    "    container.style.fontSize = '2em';\n",
    "    container.style.fontWeight = 'bold';\n",
    "    container.style.textAlign = 'center';\n",
    "    container.style.marginBottom = '20px';\n",
    "\n",
    "    var text = 'Welcome to next level Satellite image processing!';\n",
    "    for (var i = 0; i < text.length; i++) {\n",
    "        (function(i){\n",
    "            setTimeout(function(){\n",
    "                var letter = document.createElement('span');\n",
    "                letter.style.opacity = '0';\n",
    "                letter.style.transition = 'opacity 0.1s';\n",
    "                letter.innerText = text[i];\n",
    "\n",
    "                container.appendChild(letter);\n",
    "\n",
    "                setTimeout(function() {\n",
    "                    letter.style.opacity = '1';\n",
    "                }, 20);\n",
    "            }, i * 100);\n",
    "        })(i);\n",
    "    }\n",
    "\n",
    "    var gradioContainer = document.querySelector('.gradio-container');\n",
    "    gradioContainer.insertBefore(container, gradioContainer.firstChild);\n",
    "\n",
    "    return 'Animation created';\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Create the Gradio app\n",
    "with gr.Blocks(css=css_style, theme=gr.themes.Base(), js=js) as demo:\n",
    "    with gr.Row():\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Row():\n",
    "                # gr.Button(\"Create a new location\")\n",
    "                # TODO Preselect port Amsterdam\n",
    "                location_selection = gr.Dropdown(\n",
    "                    value=None,\n",
    "                    choices=list(locations_dict.keys()),\n",
    "                    label=\"Recent Locations\",\n",
    "                    interactive=True,\n",
    "                    elem_classes=\"gr-dropdown\"  # Class added\n",
    "                    \n",
    "                )\n",
    "                prompt_input = gr.Text('', label=\"Prompt\", elem_classes=\"gr-input\")  # Class added)\n",
    "            with gr.Row():\n",
    "                gr.Markdown(\"Selected Area\")\n",
    "                gr.Markdown(\"Description about the selected area\")\n",
    "            with gr.Row():\n",
    "                image_display = gr.Image(label=None, interactive=False, width=500, height=500, elem_classes=\"image\")\n",
    "                with gr.Column():\n",
    "                    number_of_tiles = gr.Text(\"1000x1000\", label=\"Number of tiles\", visible=False)\n",
    "                    real_size = gr.Text(\"1000x1000\", label=\"Size (meters)\", visible=False)\n",
    "            output = gr.HTML(value=\"\", elem_classes=\"gr-html\")\n",
    "            #image_display = gr.Image(label=None, interactive=False, width=500, height=500, elem_classes=\"image\")\n",
    "\n",
    "\n",
    "            threshold_value = 0.5\n",
    "            # Add an empty HTML element\n",
    "            #with gr.Row(elem_classes=\"gr-slider-container\"):\n",
    "            def update_threshold(value):\n",
    "                global threshold_value\n",
    "                threshold_value = value  # Update the global value\n",
    "            threshold_slider = gr.Slider(0, 1, value=0.5, step=0.1, label=\"Threshold\", elem_classes=\"gr-slider\", info=\"Choose a threshold between 0 and 1\", interactive=True)\n",
    "            threshold_slider.change(update_threshold, inputs=threshold_slider, outputs=[])\n",
    "\n",
    "            annotate_examples_btn = gr.Button(\"Annotate Examples\", interactive=False)\n",
    "            output = gr.HTML(value=\"<div></div>\")\n",
    "            \n",
    "\n",
    "            # Add a button to load images\n",
    "            \n",
    "\n",
    "            # Update the HTML content when the button is pressed\n",
    "\n",
    "            submit_all_button = gr.Button(\"Run\", visible=False)\n",
    "        with gr.Column():\n",
    "            chat_history = [\n",
    "             #   {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "             #   {\"role\": \"assistant\", \"content\": \"Hi there! How can I assist you today?\"},\n",
    "            ]\n",
    "            def get_chat_history():\n",
    "                return chat_history\n",
    "            # Gradio Blocks Interface\n",
    "            chatbot = gr.Chatbot(type=\"messages\", value=get_chat_history(), show_label=False)  # Load initial chat history\n",
    "\n",
    "\n",
    "            # Function to refresh chat: clear history and reload with updated messages\n",
    "\n",
    "            # Refresh Button\n",
    "            #refresh_button = gr.Button(\"Refresh Chat\")\n",
    "            # refresh_button.click(add_to_chat, inputs=[], outputs=chatbot)\n",
    "\n",
    "\n",
    "    ### Events\n",
    "    def add_to_chat(messages):\n",
    "        global chat_history\n",
    "        for role, message in messages:\n",
    "            chat_history.append({\"role\": role, \"content\": message})\n",
    "\n",
    "        return gr.update(value=chat_history)  # Update the chatbot with the new history\n",
    "\n",
    "\n",
    "    def fetch_examples(prompt_input: str, location_name: str, progress=gr.Progress()):\n",
    "        bot = initilize_bot(prompt_input)\n",
    "        #gr.Button(\"Run\", visible=True)\n",
    "        location = locations_dict[location_name]\n",
    "        progress(0.005, desc=\"Starting\")\n",
    "        api_response = process_examples(prompt_input, location, bot, threshold_value)\n",
    "        \n",
    "        assert len(api_response[0]) == 3\n",
    "\n",
    "        html_content = '<div class=\"container\">'\n",
    "        for answer, example_image, annotated_image in progress.tqdm(api_response, desc=\"Processing example images\"):\n",
    "            gr.HTML(value=\"<div></div>\")\n",
    "                #with open(image_path, \"rb\") as img_file:\n",
    "                #    base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "            base64_image = pil_to_base64(example_image)    \n",
    "            html_content += f\"\"\"\n",
    "            <div class=\"row_s\">\n",
    "                <div class=\"image\"><img src=\"data:image/png;base64,{base64_image}\"></div>\n",
    "                {\n",
    "                    \"\" if annotated_image is None else f'<div class=\"image\"><img src=\"data:image/png;base64,{pil_to_base64(annotated_image)}\"></div>'\n",
    "                }\n",
    "\n",
    "                <div class=\"index\">{answer}</div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "\n",
    "        html_content += \"</div>\"\n",
    "        return html_content, gr.Button(f\"Run query on all {len(location.tiles)} tiles\", visible=True)\n",
    "    # submit_button.click(fetch_examples, inputs=[prompt_input, location_selection], outputs=output)\n",
    "\n",
    "    annotate_examples_btn.click(fetch_examples, inputs=[prompt_input, location_selection], outputs=[output, submit_all_button])\n",
    "\n",
    "\n",
    "    def show_button():\n",
    "        return gr.HTML('')\n",
    "    submit_all_button.click(show_button, inputs=[], outputs=[output])\n",
    "\n",
    "    def submit_all(prompt_input: str, location_name: str, progress=gr.Progress()):\n",
    "        bot = initilize_bot(prompt_input)\n",
    "        progress(0.05, desc=\"Starting\")\n",
    "        location = locations_dict[location_name]\n",
    "        vals = [process_individual(prompt_input, tile, bot) for tile in progress.tqdm(list(location.tiles.values()), desc=\"Processing the images\")]\n",
    "        new_vals = [float(val[0]) for val in vals]\n",
    "        \n",
    "        gr.Text(f\"Total_num: {sum(new_vals)}\")\n",
    "        gr.Text(f\"Total: {vals}\")\n",
    "        messages = [(\"user\", prompt_input), (\"assistant\", f\"At location {location_name}, I see {sum(new_vals)} in total.\")]\n",
    "        return add_to_chat(messages)\n",
    "    \n",
    "    submit_all_button.click(submit_all, inputs=[prompt_input, location_selection], outputs=[chatbot])\n",
    "    def hide_submit_all_button():\n",
    "        return gr.Button(\"\", visible=False)\n",
    "    submit_all_button.click(hide_submit_all_button, inputs=[], outputs=[submit_all_button])\n",
    "\n",
    "    def on_location_selected(location_name: str, prompt):\n",
    "        location = locations_dict[location_name]\n",
    "        should_be_interactive = prompt != \"\" and location_name != \"\"\n",
    "        area = calculate_distance_components(location.top_left, location.bottom_right)\n",
    "        real_size_str = area\n",
    "        return location.thumbnail, gr.Button(\"Annotate Examples\", interactive=should_be_interactive), gr.Text(real_size_str, label=\"Size (meters)\", visible=True), gr.Text(str(len(location.tiles)), label=\"Number of tiles\", visible=True)\n",
    "    \n",
    "    def on_prompt_input(prompt: str, location_name: str):\n",
    "        #location = locations_dict[location_name]\n",
    "        should_be_interactive = prompt != \"\" and location_name != \"\"\n",
    "        return gr.Button(\"Annotate Examples\", interactive=should_be_interactive)\n",
    "    location_selection.change(on_location_selected, inputs=[location_selection, prompt_input], outputs=[image_display, annotate_examples_btn, real_size, number_of_tiles,])\n",
    "    prompt_input.change(on_prompt_input, inputs=[location_selection, prompt_input], outputs=annotate_examples_btn)\n",
    "# Run the app\n",
    "demo.launch()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
